We will now implement the EM algorithm for the case where we have missing data in a multivariate normal distribution. We will work with fake data that we generate ourselves, so that we can test how we the approach works. 
Let's begin by generating 500 observations from a $k$ dimensional MVN distribution with mean $\mu = (1, 2, \ldots, k)$ with covariance matrix
$$\Sigma_{ij} = \sqrt{ij} \left(1-\frac{i-j}{k}\right)$$
  which says let the variance increase as we go through the dimensions, and let adjacent values be most closely related. See data plot.
  
```{r, echo=F}
set.seed(12)
```
  
```{r}
k <- 4  # dim y
mu <- seq(1:k)

Sigma <- matrix(nr=k,nc=k)
for(i in 1:k){
  for(j in 1:k){
    Sigma[i,j] = (1-abs(i-j)/k)*sqrt(i*j)
  }
}
Sigma
cov2cor(Sigma)
```
To generate data, we can use the rmvnorm package.

```{r}
library(mvtnorm)
nsamps <- 500
Y <- rmvnorm(n = nsamps, mean=mu, sigma = Sigma)
pairs(Y)
```

To get an idea of what the mean and covriance matrix would be if we estimated them using the full data, let's look at

```{r}
ybar <- apply(Y,2, mean)
#Ycent <- sweep(Y, 2, ybar, '-') # remiove the mean from each Y
#1/nsamps *t(Ycent)%*%Ycent # for the MLE we divide by n not n-1
cov(Y)*(nsamps-1)/nsamps 
1/nsamps* t(Y)%*%Y - ybar%*%t(ybar) # check it agrees with cov(Y)
```

Now finally let's remove some data to give us a missing-dataset.



```{r}
missingfreq <- 0.3
M <- matrix(as.logical(rbinom(nsamps*k,1,missingfreq)), nr=nsamps)
Ymis <- Y
Ymis[M] <- NA
```

# EM algorithm

We will now only work with the missing data. We need to implement functions to calculate the expected values described in section 6.5 of the notes. To begin with, let's calculate
$$E(y|y_{obs}, \theta)$$

```{r}
expectY <- function(y, mu, Sigma){
  #
  # function to calculate 
  # E(y|y_obs, theta^{m})
  #
  miss.pat <- is.na(y) # find pattern of missingness
  if(sum(miss.pat) ==0) return(y) ## i.e. no missing data, 
                      #so just return observation
  if(sum(miss.pat)==k) return(mu) ## both observations missing, so return mean
  else{
    # only if we have a mixture of observed and unobserved data do we need the conditional
    # Gaussian formalue
    tmp <- y
    tmp[is.na(tmp)] <- mu[miss.pat] + Sigma[miss.pat,!miss.pat]%*% 
      solve(Sigma[!miss.pat, !miss.pat])%*%(y[!miss.pat]- mu[!miss.pat])
    return(tmp)
  }
}
```

This function only works on a single observation at a time. We can then loop over all the rows in the data matrix using
```{r}
Yexp <- t(apply(Ymis,1, expectY, mu=mu, Sigma=Sigma))
```

Next, we need a function to calculate the variance.  We can do this as follows

```{r}
varY <- function(y, mu, Sigma){
  #
  # function to calculate 
  # V(y | y_obs, theta)
  #

  miss.pat <- is.na(y) # find pattern of missingness
  if(sum(miss.pat) ==0) return(matrix(rep(0,k^2), nr=k)) ## i.e. no missing data, 
                      #### so just return observation
  if(sum(miss.pat)==k) return(Sigma) ## both observations missing, so return mean
  else{
    # only if we have a mixture of observed and unobserved data do we need the conditional
    # Gaussian formalue
    tmp <- matrix(rep(0,k^2),nr=k)
    tmp[miss.pat, miss.pat] <-  Sigma[miss.pat, miss.pat] - Sigma[miss.pat,!miss.pat]%*% 
      solve(Sigma[!miss.pat, !miss.pat]) %*%Sigma[!miss.pat, miss.pat]
    return(tmp)
  }
}
```

Then we calculate calculate 
$$E(yy^\top|y_{obs}, \theta)$$
using 
```{r}

expYYt <- function(y, mu, Sigma){
  #
  # this function calculate E(y y^t | y_obs, theta)
  #

  tmp <- expectY(y,mu,Sigma)
  varY(y,mu, Sigma) + tmp%*%t(tmp)
}
```
and again, we need to loop over all the
 rows of Ymis

```{r}
S <- matrix(nr=k,rep(0,k^2))
for(i in 1:nsamps){
  S <- S+expYYt(Ymis[i,], mu=mu, Sigma=Sigma)
}
```

Finally, we need to loop over all of these steps until convergence. We will use available-case analysis to estimate initial values of the parameters.

```{r}

EM <- function(Ymis){
  k = dim(Ymis)[2]
  n=dim(Ymis)[1]
  mu0 <- apply(Ymis,2, mean, na.rm=T)  # available-case estimate of the mean
  Sigma0 <- cov(Ymis, use='pairwise.complete.obs')   # available-case estimate of the variance
  mu.list <- list()
  mu.list[[1]] <- mu0
  
  Sigma.list <- list()
  Sigma.list[[1]]<- Sigma0   
  
  change <-1
  
  i<-1
  while(change>10^-6 && i<=500){
    Yexp <- t(apply(Ymis,1, expectY, mu=mu.list[[i]], Sigma=Sigma.list[[i]]))
    mu.list[[i+1]] <- apply(Yexp,2,mean)
    S <- matrix(nr=k,rep(0,k^2))
    for(j in 1:n){
      S <- S+expYYt(Yexp[j,], mu=mu.list[[i+1]], Sigma=Sigma.list[[i]])
    }
    Sigma.list[[i+1]] <- S/n - mu.list[[i+1]]%*%t(mu.list[[i+1]])
    
    change <- max(max(abs(mu.list[[i+1]]-mu.list[[i]])), max(abs(Sigma.list[[i+1]]-Sigma.list[[i]])))
    i<-i+1
  }
  
  return(list(mu=mu.list[[i]], Sigma = Sigma.list[[i]]))
}
```

Finally, we can run the algorithm.
```{r}
out <- EM(Ymis)
out
```

We can  compare these with the true values
```{r}
mu
Sigma
```

# Complete case analysis
Complete case analysis works here by deleting any $y_i$ which has a single missing entry. If the rate of missingness is large compared to $k$, then we can find we have very few cases to work with. 

```{r}
Ycomplete <- Ymis[complete.cases(Ymis),]
colMeans(Ycomplete)
cov(Ycomplete)
print(paste('Complete case analysis is based on only', dim(Ycomplete)[1],'samples!'))
```

Available case analysis works reasonably well in this case.
```{r}
apply(Ymis,2, mean, na.rm=T)
cov(Ymis, use='pairwise.complete.obs')
```

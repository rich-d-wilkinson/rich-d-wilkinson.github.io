<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Multidimensional Scaling (MDS) | Multivariate Statistics</title>
  <meta name="description" content="The lecture notes for MATH3030/4068: Multivariate Analysis / Applied Multivariate Statistics" />
  <meta name="generator" content="bookdown 0.24.4 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Multidimensional Scaling (MDS) | Multivariate Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The lecture notes for MATH3030/4068: Multivariate Analysis / Applied Multivariate Statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Multidimensional Scaling (MDS) | Multivariate Statistics" />
  
  <meta name="twitter:description" content="The lecture notes for MATH3030/4068: Multivariate Analysis / Applied Multivariate Statistics" />
  

<meta name="author" content="Prof.Â Richard Wilkinson" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="0.2-exercises.html"/>
<link rel="next" href="1.1-classical-mds.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied multivariate statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="0.1" data-path="0.1-computer-tasks.html"><a href="0.1-computer-tasks.html"><i class="fa fa-check"></i><b>0.1</b> Computer tasks</a></li>
<li class="chapter" data-level="0.2" data-path="0.2-exercises.html"><a href="0.2-exercises.html"><i class="fa fa-check"></i><b>0.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-mds.html"><a href="1-mds.html"><i class="fa fa-check"></i><b>1</b> Multidimensional Scaling (MDS)</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1.1-classical-mds.html"><a href="1.1-classical-mds.html"><i class="fa fa-check"></i><b>1.1</b> Classical MDS</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="1.1-classical-mds.html"><a href="1.1-classical-mds.html#non-euclidean-distance-matrices"><i class="fa fa-check"></i><b>1.1.1</b> Non-Euclidean distance matrices</a></li>
<li class="chapter" data-level="1.1.2" data-path="1.1-classical-mds.html"><a href="1.1-classical-mds.html#principal-coordinate-analysis"><i class="fa fa-check"></i><b>1.1.2</b> Principal Coordinate Analysis</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1.2-similarity.html"><a href="1.2-similarity.html"><i class="fa fa-check"></i><b>1.2</b> Similarity measures</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="1.2-similarity.html"><a href="1.2-similarity.html#binary-attributes"><i class="fa fa-check"></i><b>1.2.1</b> Binary attributes</a></li>
<li class="chapter" data-level="1.2.2" data-path="1.2-similarity.html"><a href="1.2-similarity.html#example-classical-mds-with-the-mnist-data"><i class="fa fa-check"></i><b>1.2.2</b> Example: Classical MDS with the MNIST data</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1.3-non-metric-mds.html"><a href="1.3-non-metric-mds.html"><i class="fa fa-check"></i><b>1.3</b> Non-metric MDS</a></li>
<li class="chapter" data-level="1.4" data-path="1.4-exercises-1.html"><a href="1.4-exercises-1.html"><i class="fa fa-check"></i><b>1.4</b> Exercises</a></li>
<li class="chapter" data-level="1.5" data-path="1.5-computer-tasks-1.html"><a href="1.5-computer-tasks-1.html"><i class="fa fa-check"></i><b>1.5</b> Computer Tasks</a></li>
</ul></li>
<li class="divider"></li>
<li> <a href="https://rich-d-wilkinson.github.io/teaching.html" target="blank">University of Nottingham</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Multivariate Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mds" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Multidimensional Scaling (MDS)</h1>
<!-- 
LOOK AT 
http://simbad-fp7.eu/images/tutorial/02-ECCV2012Tutorial.pdf
-->
<p>The videos for this chapter are available at:</p>
<ul>
<li><a href="https://mediaspace.nottingham.ac.uk/media/MDSA+Introduction/1_k5ofxt3k">6.0 Introduction to MDS</a></li>
<li><a href="https://mediaspace.nottingham.ac.uk/media/MDSA+Classical+MDS/1_0lz9sce2">6.1 Classical MDS</a></li>
<li><a href="https://mediaspace.nottingham.ac.uk/media/MDSA+Example+1/1_y5cp5ea6">6.1 Example 1</a></li>
<li><a href="https://mediaspace.nottingham.ac.uk/media/MDSA+Non-Euclidean+distance+matrices/1_nsh2vdgr">6.1.1 Non-Euclidean distance matrices</a></li>
<li><a href="https://mediaspace.nottingham.ac.uk/media/MDSA+Principal+Coordinate+Analysis/1_r07on81w">6.1.2 Principal Coordinate Analysis</a></li>
<li><a href="https://mediaspace.nottingham.ac.uk/media/MDSA+Similarity+matrices/1_wwuwwxk4">6.2 Similarity measures</a></li>
<li><a href="https://mediaspace.nottingham.ac.uk/media/MDSA+Binary+Attributes/1_jfx45kk0">6.2.1 Binary attributes</a></li>
<li><a href="https://mediaspace.nottingham.ac.uk/media/MDSA+Non+metric+MDS/1_jqzo1xi4">6.3 Non-metric MDS</a></li>
</ul>
<p>In PCA, we start with <span class="math inline">\(n\)</span> data points <span class="math inline">\(\mathbf x_i \in \mathbb{R}^p\)</span>, and then try to find a low dimensional projection of these points, e.g., <span class="math inline">\(\mathbf y_1, \ldots, \mathbf y_n \in \mathbb{R}^r\)</span> with <span class="math inline">\(r&lt;p\)</span>, in such a way that they minimize the reconstruction error (or maximize the variance).</p>
<p>The focus in <strong>Multidimensional Scaling (MDS)</strong> is somewhat different. Instead of being given the data <span class="math inline">\(\mathbf X\)</span>, our starting point is often a matrix of <strong>distances</strong> or <strong>dissimilarities</strong> between the data points, <span class="math inline">\(\mathbf D\)</span>. For example, if we have data on <span class="math inline">\(n\)</span> different experimental units, then we would be given the distances <span class="math inline">\(d_{ij}\)</span> between any pair of experimental units <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>. We compile these into a <span class="math inline">\(n\times n\)</span> <strong>distance matrix</strong> <span class="math inline">\(\mathbf D=(d_{ij}: \, i,j=1, \ldots , n)\)</span>.</p>
<p>The goal of MDS is to find a set of points in a low-dimensional Euclidean space <span class="math inline">\(\mathbb{R}^r\)</span>, usually <span class="math inline">\(\mathbb{R}\)</span> or <span class="math inline">\(\mathbb{R}^2\)</span>, whose inter-point distances (or dissimilarities) are as close as possible to the <span class="math inline">\(d_{ij}\)</span>. That is, we want to find <span class="math inline">\(\mathbf y_1, \ldots, \mathbf y_n \in \mathbb{R}^r\)</span> whose distance matrix is approximately <span class="math inline">\(\mathbf D\)</span>, i.e., for which
<span class="math display">\[\operatorname{distance}(\mathbf y_i, \mathbf y_j) \approx d_{ij}.\]</span>
In other words, we are trying to create a spatial representation of the data, <span class="math inline">\(\mathbf y_1, \ldots, \mathbf y_n\)</span>, from a distance matrix <span class="math inline">\(\mathbf D\)</span>. The vectors <span class="math inline">\(\mathbf y_i\)</span> have no meaning by themselves, but by visualising their spatial pattern we can hope to learn something about the dataset represented by <span class="math inline">\(\mathbf D\)</span>.</p>
<p>If we define the errors in terms of a square distance, then we can write the goal of MDS as the following optimization problem:
<span class="math display" id="eq:mdsopt">\[\begin{align}
\mbox{Find} \quad&amp; \mathbf y_1, \ldots, \mathbf y_k \in \mathbb{R}^r\\
\mbox{to minimize} \quad &amp;\sum_{i=1}^n \sum_{j=1}^n (d_{ij} - d(\mathbf y_i, \mathbf y_j))^2.\tag{1.1}
\end{align}\]</span></p>
<p>As an illustrative example, consider the location of some of Englandâs cities.</p>
<p><img src="06-mds_files/figure-html/unnamed-chunk-1-1.png" width="576" /></p>
<p>If we are told their latitude and longitude, it is easy to calculate the distances between the cities. I.e., given the latitude and longitude of each city, <span class="math inline">\(\mathbf x_i\)</span>, we can compute the distance matrix between pairs of cities <span class="math inline">\(\mathbf D\)</span>:</p>
<table class="table" style="font-size: 7px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
London
</th>
<th style="text-align:right;">
Birmingham
</th>
<th style="text-align:right;">
Manchester
</th>
<th style="text-align:right;">
Leeds
</th>
<th style="text-align:right;">
Newcastle
</th>
<th style="text-align:right;">
Liverpool
</th>
<th style="text-align:right;">
Portsmouth
</th>
<th style="text-align:right;">
Southampton
</th>
<th style="text-align:right;">
Nottingham
</th>
<th style="text-align:right;">
Bristol
</th>
<th style="text-align:right;">
Sheffield
</th>
<th style="text-align:right;">
Norwich
</th>
<th style="text-align:right;">
Plymouth
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
London
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
163
</td>
<td style="text-align:right;">
262
</td>
<td style="text-align:right;">
273
</td>
<td style="text-align:right;">
403
</td>
<td style="text-align:right;">
286
</td>
<td style="text-align:right;">
103
</td>
<td style="text-align:right;">
112
</td>
<td style="text-align:right;">
175
</td>
<td style="text-align:right;">
170
</td>
<td style="text-align:right;">
228
</td>
<td style="text-align:right;">
159
</td>
<td style="text-align:right;">
308
</td>
</tr>
<tr>
<td style="text-align:left;">
Birmingham
</td>
<td style="text-align:right;">
163
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
114
</td>
<td style="text-align:right;">
149
</td>
<td style="text-align:right;">
282
</td>
<td style="text-align:right;">
125
</td>
<td style="text-align:right;">
195
</td>
<td style="text-align:right;">
179
</td>
<td style="text-align:right;">
73
</td>
<td style="text-align:right;">
124
</td>
<td style="text-align:right;">
105
</td>
<td style="text-align:right;">
217
</td>
<td style="text-align:right;">
281
</td>
</tr>
<tr>
<td style="text-align:left;">
Manchester
</td>
<td style="text-align:right;">
262
</td>
<td style="text-align:right;">
114
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
58
</td>
<td style="text-align:right;">
174
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
308
</td>
<td style="text-align:right;">
293
</td>
<td style="text-align:right;">
94
</td>
<td style="text-align:right;">
227
</td>
<td style="text-align:right;">
53
</td>
<td style="text-align:right;">
255
</td>
<td style="text-align:right;">
369
</td>
</tr>
<tr>
<td style="text-align:left;">
Leeds
</td>
<td style="text-align:right;">
273
</td>
<td style="text-align:right;">
149
</td>
<td style="text-align:right;">
58
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
135
</td>
<td style="text-align:right;">
105
</td>
<td style="text-align:right;">
335
</td>
<td style="text-align:right;">
323
</td>
<td style="text-align:right;">
98
</td>
<td style="text-align:right;">
271
</td>
<td style="text-align:right;">
47
</td>
<td style="text-align:right;">
230
</td>
<td style="text-align:right;">
420
</td>
</tr>
<tr>
<td style="text-align:left;">
Newcastle
</td>
<td style="text-align:right;">
403
</td>
<td style="text-align:right;">
282
</td>
<td style="text-align:right;">
174
</td>
<td style="text-align:right;">
135
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
199
</td>
<td style="text-align:right;">
469
</td>
<td style="text-align:right;">
458
</td>
<td style="text-align:right;">
231
</td>
<td style="text-align:right;">
401
</td>
<td style="text-align:right;">
181
</td>
<td style="text-align:right;">
328
</td>
<td style="text-align:right;">
542
</td>
</tr>
<tr>
<td style="text-align:left;">
Liverpool
</td>
<td style="text-align:right;">
286
</td>
<td style="text-align:right;">
125
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
105
</td>
<td style="text-align:right;">
199
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
317
</td>
<td style="text-align:right;">
299
</td>
<td style="text-align:right;">
132
</td>
<td style="text-align:right;">
219
</td>
<td style="text-align:right;">
101
</td>
<td style="text-align:right;">
299
</td>
<td style="text-align:right;">
346
</td>
</tr>
<tr>
<td style="text-align:left;">
Portsmouth
</td>
<td style="text-align:right;">
103
</td>
<td style="text-align:right;">
195
</td>
<td style="text-align:right;">
308
</td>
<td style="text-align:right;">
335
</td>
<td style="text-align:right;">
469
</td>
<td style="text-align:right;">
317
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
239
</td>
<td style="text-align:right;">
127
</td>
<td style="text-align:right;">
288
</td>
<td style="text-align:right;">
261
</td>
<td style="text-align:right;">
221
</td>
</tr>
<tr>
<td style="text-align:left;">
Southampton
</td>
<td style="text-align:right;">
112
</td>
<td style="text-align:right;">
179
</td>
<td style="text-align:right;">
293
</td>
<td style="text-align:right;">
323
</td>
<td style="text-align:right;">
458
</td>
<td style="text-align:right;">
299
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
229
</td>
<td style="text-align:right;">
103
</td>
<td style="text-align:right;">
276
</td>
<td style="text-align:right;">
268
</td>
<td style="text-align:right;">
202
</td>
</tr>
<tr>
<td style="text-align:left;">
Nottingham
</td>
<td style="text-align:right;">
175
</td>
<td style="text-align:right;">
73
</td>
<td style="text-align:right;">
94
</td>
<td style="text-align:right;">
98
</td>
<td style="text-align:right;">
231
</td>
<td style="text-align:right;">
132
</td>
<td style="text-align:right;">
239
</td>
<td style="text-align:right;">
229
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
193
</td>
<td style="text-align:right;">
53
</td>
<td style="text-align:right;">
169
</td>
<td style="text-align:right;">
353
</td>
</tr>
<tr>
<td style="text-align:left;">
Bristol
</td>
<td style="text-align:right;">
170
</td>
<td style="text-align:right;">
124
</td>
<td style="text-align:right;">
227
</td>
<td style="text-align:right;">
271
</td>
<td style="text-align:right;">
401
</td>
<td style="text-align:right;">
219
</td>
<td style="text-align:right;">
127
</td>
<td style="text-align:right;">
103
</td>
<td style="text-align:right;">
193
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
228
</td>
<td style="text-align:right;">
296
</td>
<td style="text-align:right;">
162
</td>
</tr>
<tr>
<td style="text-align:left;">
Sheffield
</td>
<td style="text-align:right;">
228
</td>
<td style="text-align:right;">
105
</td>
<td style="text-align:right;">
53
</td>
<td style="text-align:right;">
47
</td>
<td style="text-align:right;">
181
</td>
<td style="text-align:right;">
101
</td>
<td style="text-align:right;">
288
</td>
<td style="text-align:right;">
276
</td>
<td style="text-align:right;">
53
</td>
<td style="text-align:right;">
228
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
203
</td>
<td style="text-align:right;">
382
</td>
</tr>
<tr>
<td style="text-align:left;">
Norwich
</td>
<td style="text-align:right;">
159
</td>
<td style="text-align:right;">
217
</td>
<td style="text-align:right;">
255
</td>
<td style="text-align:right;">
230
</td>
<td style="text-align:right;">
328
</td>
<td style="text-align:right;">
299
</td>
<td style="text-align:right;">
261
</td>
<td style="text-align:right;">
268
</td>
<td style="text-align:right;">
169
</td>
<td style="text-align:right;">
296
</td>
<td style="text-align:right;">
203
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
453
</td>
</tr>
<tr>
<td style="text-align:left;">
Plymouth
</td>
<td style="text-align:right;">
308
</td>
<td style="text-align:right;">
281
</td>
<td style="text-align:right;">
369
</td>
<td style="text-align:right;">
420
</td>
<td style="text-align:right;">
542
</td>
<td style="text-align:right;">
346
</td>
<td style="text-align:right;">
221
</td>
<td style="text-align:right;">
202
</td>
<td style="text-align:right;">
353
</td>
<td style="text-align:right;">
162
</td>
<td style="text-align:right;">
382
</td>
<td style="text-align:right;">
453
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<p>But can we do the reverse and construct a map from the distance matrix? This is the aim of multidimensional scaling:
MDS constructs a set of points, <span class="math inline">\(\mathbf y_1, \ldots, \mathbf y_n\)</span>, that have distances between them given by the distance matrix <span class="math inline">\(\mathbf D\)</span>. In other words, it creates a map with a set of coordinates for which the distances between points are approximately the same as in the real data.</p>
<p>Of course, this illustrative example is not very interesting, as the original data (the city locations) are only two-dimensional, but in problems with high dimensional data, finding a way to
represent the points in a low-dimensional space will make visualization and statistical analysis easier. We shall see, perhaps unsurprisingly, that there is a close connection between MDS and PCA.</p>
<div id="notation" class="section level4 unnumbered">
<h4>Notation</h4>
<p>There are many ways to compute distances between points. For example, you may have studied metrics previously, which are distance functions that satisfy certain axioms. In MDS, we do not need to work with distances that are metrics (although sometimes we do), and instead we only require that distances satisfy a weaker set of conditions:</p>

<div class="definition">
<p><span id="def:distanceD" class="definition"><strong>Definition 1.1  </strong></span>The <span class="math inline">\(n \times n\)</span> matrix <span class="math inline">\(\mathbf D=(d_{ij})_{i,j=1}^n\)</span> is a <strong>distance matrix</strong> (sometimes called a <strong>dissimilarity matrix</strong>) if</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(d_{ij}\geq 0\)</span> for all <span class="math inline">\(i, j=1,\ldots,n\)</span>.</li>
<li><span class="math inline">\(d_{ii}=0\)</span> for <span class="math inline">\(i=1,\ldots, n\)</span> and</li>
<li><span class="math inline">\(\mathbf D=\mathbf D^\top\)</span>, i.e., <span class="math inline">\(\mathbf D\)</span> is symmetric (<span class="math inline">\(d_{ij}=d_{ji}\)</span>).
<!--4.  $d_{ij}=0$ implies $\bx_i=\bx_j$--> <!-- I don't think this is neeeded anywhjere. And the proof of similarity matrices can't prove this part -->
</div></li>
</ol>
<p>Note that we do not require distances to necessarily satisfy the triangle inequality
<span class="math display" id="eq:triangle">\[\begin{equation}
d_{ik} \leq d_{ij}+d_{jk}.
\tag{1.2}
\end{equation}\]</span>
A distance function which always satisfies the triangle inequality is called a <strong>metric distance</strong>
or just a <strong>metric</strong>. A distance function which does not always satisfy the triangle inequality is called a
<strong>non-metric</strong> distance.</p>
<!--
There are many types of MDS method. 
- Classical MDS works with Euclidean distances
- Metric MDS 
-->
<p>There are many ways to measure distance. Two common choices of metric distances are</p>
<ul>
<li>Euclidean distance <span class="math inline">\(||\mathbf x-\mathbf x&#39;||_2\)</span>, also know as the âcrow fliesâ distance.</li>
<li><span class="math inline">\(L_1\)</span> distance <span class="math inline">\(||\mathbf x-\mathbf x&#39;||_1\)</span>, sometimes called the Manhattan or taxicab metric.</li>
</ul>
<p>But for the city data, we could also consider distance by road, i.e., we could measure the minimum distance by road between each pair of cities. This would satisfy the axioms for being a distance, but is not a metric distance</p>
<p>The choice of which distance is appropriate is problem specific (see section <a href="1.2-similarity.html#similarity">1.2</a> for an example). The focus in this chapter is on Euclidean distance, as this leads to an explicit mathematical solution to the optimization problem <a href="1-mds.html#eq:mdsopt">(1.1)</a>. However, note that MDS techniques have also been developed for non-Euclidean distances.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="0.2-exercises.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="1.1-classical-mds.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MultivariateStatistics.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
},
"pandoc_args": "--top-level-division=[chapter|part]"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

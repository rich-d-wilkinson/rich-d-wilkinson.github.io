<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.2 The sample ML discriminant rule | Multivariate Statistics</title>
  <meta name="description" content="The lecture notes for MATH3030/4068: Multivariate Analysis / Applied Multivariate Statistics" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="1.2 The sample ML discriminant rule | Multivariate Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The lecture notes for MATH3030/4068: Multivariate Analysis / Applied Multivariate Statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.2 The sample ML discriminant rule | Multivariate Statistics" />
  
  <meta name="twitter:description" content="The lecture notes for MATH3030/4068: Multivariate Analysis / Applied Multivariate Statistics" />
  

<meta name="author" content="Prof. Richard Wilkinson" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="1-1-lda-ML.html"/>
<link rel="next" href="1-3-fishers-linear-discriminant-rule.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied multivariate statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="part-iv-classification-and-clustering.html"><a href="part-iv-classification-and-clustering.html"><i class="fa fa-check"></i>Part IV: Classification and Clustering</a></li>
<li class="chapter" data-level="1" data-path="1-lda.html"><a href="1-lda.html"><i class="fa fa-check"></i><b>1</b> Discriminant analysis</a><ul>
<li class="chapter" data-level="1.1" data-path="1-1-lda-ML.html"><a href="1-1-lda-ML.html"><i class="fa fa-check"></i><b>1.1</b> Maximum likelihood discriminant rule</a></li>
<li class="chapter" data-level="1.2" data-path="1-2-the-sample-ml-discriminant-rule.html"><a href="1-2-the-sample-ml-discriminant-rule.html"><i class="fa fa-check"></i><b>1.2</b> The sample ML discriminant rule</a></li>
<li class="chapter" data-level="1.3" data-path="1-3-fishers-linear-discriminant-rule.html"><a href="1-3-fishers-linear-discriminant-rule.html"><i class="fa fa-check"></i><b>1.3</b> Fisher’s linear discriminant rule</a></li>
<li class="chapter" data-level="1.4" data-path="1-4-probability-of-misclassification.html"><a href="1-4-probability-of-misclassification.html"><i class="fa fa-check"></i><b>1.4</b> Probability of misclassification</a></li>
<li class="chapter" data-level="1.5" data-path="1-5-computer-tasks.html"><a href="1-5-computer-tasks.html"><i class="fa fa-check"></i><b>1.5</b> Computer tasks</a></li>
<li class="chapter" data-level="1.6" data-path="1-6-exercises.html"><a href="1-6-exercises.html"><i class="fa fa-check"></i><b>1.6</b> Exercises</a></li>
</ul></li>
<li class="divider"></li>
<li> <a href="https://rich-d-wilkinson.github.io/teaching.html" target="blank">University of Nottingham</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Multivariate Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-sample-ml-discriminant-rule" class="section level2">
<h2><span class="header-section-number">1.2</span> The sample ML discriminant rule</h2>
<p>To use the ML discriminant rule, above, we need to know the model parameters for each group. In reality, we often do not know these parameters but we can estimate them from ``training’’ data. Training data typically consists of samples <span class="math inline">\(\mathbf x_{1,j}, \ldots, \mathbf x_{n_j,j}\)</span> known to be from population <span class="math inline">\(\Pi_j\)</span> (<span class="math inline">\(j=1,\ldots ,g\)</span>). Note that there are <span class="math inline">\(n_j\)</span> observations from population <span class="math inline">\(\Pi_j\)</span>.</p>
<p>For simplicity, we shall assume that the populations have multivariate normal distributions with different means <span class="math inline">\({\boldsymbol{\mu}}_j\)</span>, <span class="math inline">\(j=1,\ldots,g\)</span>, and the same covariance matrix, <span class="math inline">\(\boldsymbol{\Sigma}\)</span>. Let <span class="math inline">\(\bar{\mathbf x}_j\)</span> and <span class="math inline">\(\mathbf S_j\)</span> be the sample mean and sample covariance matrix for the <span class="math inline">\(j\)</span>th group. Then <span class="math inline">\(\bar{\mathbf x}_j\)</span> is an unbiased estimate of <span class="math inline">\({\boldsymbol{\mu}}_j\)</span> and
<span class="math display">\[\mathbf S_u = \frac{1}{n-g} \sum_{k=1}^g n_k \mathbf S_k\]</span>
is an unbiased estimate of <span class="math inline">\(\boldsymbol{\Sigma}\)</span> where <span class="math inline">\(n = n_1 + n_2 + \ldots + n_g\)</span>. The sample ML discriminant rule is then defined by substituting these estimates into <a href="1-1-lda-ML.html#prp:nine1">1.1</a>.</p>

<div class="definition">
<span id="def:sampleML" class="definition"><strong>Definition 1.2  </strong></span>If <span class="math inline">\(\Pi_k\)</span> is the <span class="math inline">\(N_p({\boldsymbol{\mu}}_k,\boldsymbol{\Sigma})\)</span> population, <span class="math inline">\(k=1,\ldots,g\)</span>, then the sample ML discriminant rule allocates <span class="math inline">\(\mathbf z\)</span> to <span class="math inline">\(\Pi_j\)</span> where $j $ is the value of <span class="math inline">\(k\)</span> which minimises
<span class="math display">\[(\mathbf z-\bar{\mathbf x}_k)^\top \mathbf S_u^{-1} (\mathbf z-\bar{\mathbf x}_k).\]</span>
</div>

<p>In the case <span class="math inline">\(g=2\)</span>, the rule allocates <span class="math inline">\(\mathbf z\)</span> to <span class="math inline">\(\Pi_1\)</span> if and only if
<span class="math display">\[\hat{\mathbf a}^\top (\mathbf z- \hat{\mathbf h}) &gt; 0\]</span>
where <span class="math inline">\(\hat{\mathbf a} = \mathbf S_u^{-1} (\bar{\mathbf x}_1 - \bar{\mathbf x}_2)\)</span>, <span class="math inline">\(\hat{\mathbf h} = \frac{1}{2} (\bar{\mathbf x}_1 + \bar{\mathbf x}_2)\)</span> and <span class="math inline">\(\mathbf S_u\)</span>, the pooled estimate of <span class="math inline">\(\boldsymbol{\Sigma}\)</span>, is given by
<span class="math display">\[ \mathbf S_u =  \frac{1}{n_1 + n_2 -2} (n_1 \mathbf S_1 + n_2 \mathbf S_2 ).\]</span></p>
<p>This is analogous to the Corollary following Proposition <a href="1-1-lda-ML.html#prp:nine1">1.1</a>.</p>

<div class="example">
<p><span id="exm:exnine4" class="example"><strong>Example 1.4  </strong></span>Consider the G11PRB and G11STA module marks for <span class="math inline">\(n_1 = 98\)</span> students on G100 and <span class="math inline">\(n_2 = 46\)</span> students on G103. The sample means and variances for each group are given by
<span class="math display">\[\begin{eqnarray*}
\bar{\mathbf x}_1 = \begin{pmatrix} 60.582 \\ 62.786 \end{pmatrix} &amp;\qquad&amp; \bar{\mathbf x}_2 = \begin{pmatrix} 64.761 \\ 60.457 \end{pmatrix} \\
\mathbf S_1 = \begin{pmatrix} 201.04 &amp; 129.56 \\ 129.56 &amp; 316.21 \end{pmatrix} &amp;\qquad&amp; \mathbf S_2 = \begin{pmatrix} 229.88 &amp; 177.02 \\ 177.02 &amp; 354.16 \end{pmatrix}
\end{eqnarray*}\]</span>
Hence,
<span class="math display">\[\begin{eqnarray*}
\mathbf S_u &amp;=&amp; \frac{1}{98+46-2} \left(98 \mathbf S_1 + 46 \mathbf S_2 \right)= \begin{pmatrix} 213.21 &amp; 146.76 \\ 146.76 &amp; 332.96 \end{pmatrix}, \\
\bar{\mathbf x}_1 - \bar{\mathbf x}_2 &amp;=&amp; \begin{pmatrix} -4.179 \\ 2.329 \end{pmatrix}, \\
\hat{\mathbf h} &amp;=&amp; \frac{1}{2} (\bar{\mathbf x}_1 + \bar{\mathbf x}_2) = \begin{pmatrix} 62.671 \\ 61.621 \end{pmatrix},
\end{eqnarray*}\]</span>
and
<span class="math display">\[\hat{\mathbf a} = \mathbf S_u^{-1} (\bar{\mathbf x}_1 - \bar{\mathbf x}_2) = \begin{pmatrix} 0.0067 &amp; -0.0030 \\ -0.0030 &amp; 0.0043 \end{pmatrix} \begin{pmatrix} -4.179 \\ 2.329 \end{pmatrix} = \begin{pmatrix} -0.035 \\ 0.022 \end{pmatrix}.\]</span></p>
<p>The sample ML discriminant rule allocates a new observation\
<span class="math inline">\(\mathbf z= (z_1, z_2)^\top\)</span> to <span class="math inline">\(\Pi_1\)</span> if and only if
<span class="math display">\[ \hat{\mathbf a}^\top (\mathbf z- \hat{\mathbf h}) = \begin{pmatrix} -0.035 &amp; 0.022 \end{pmatrix} \begin{pmatrix} z_1 - 62.671 \\ z_2 - 61.621 \end{pmatrix} &gt; 0.\]</span></p>
<p>For example, if a student on this year’s course scores 80 on G11PRB and 60 on G11STA then
<span class="math display">\[ \hat{\mathbf a}^\top (\mathbf z- \hat{\mathbf h}) = \begin{pmatrix} -0.035 &amp; 0.022 \end{pmatrix} \begin{pmatrix} 80 - 62.671 \\ 60 - 61.621 \end{pmatrix} = -0.644 &lt; 0,\]</span>
and so we would allocate this student to G103. The boundary, where <span class="math inline">\(\hat{\mathbf a}^\top (\mathbf z- \hat{\mathbf h}) = 0\)</span>, is shown below.</p>
<p>FIX
<!--
\begin{center}
\includegraphics[width=12cm,angle=0]{sample_mldr1.pdf}
\end{center}
--></p>
<p>Note that the boundary line passes half-way between the two sample means. In this example it is difficult to discriminate accurately between G100 and G103 because there is a large overlap between the two populations.</p>
<p>We could extend the example to include, say, students on GL11. Here the boundary between the three populations is piece-wise linear and they meet at a common point.</p>
FIX
<!--
\begin{center}
\includegraphics[width=12cm,angle=0]{sample_mldr2.pdf}
\end{center}
-->
</div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="1-1-lda-ML.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="1-3-fishers-linear-discriminant-rule.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MultivariateStatistics.pdf"],
"toc": {
"collapse": "section"
},
"pandoc_args": "--top-level-division=[chapter|part]"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

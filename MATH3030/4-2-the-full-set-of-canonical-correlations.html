<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.2 The full set of canonical correlations | Multivariate Statistics</title>
  <meta name="description" content="The lecture notes for MATH3030/4068: Multivariate Analysis / Applied Multivariate Statistics" />
  <meta name="generator" content="bookdown 0.20.6 and GitBook 2.6.7" />

  <meta property="og:title" content="4.2 The full set of canonical correlations | Multivariate Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The lecture notes for MATH3030/4068: Multivariate Analysis / Applied Multivariate Statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.2 The full set of canonical correlations | Multivariate Statistics" />
  
  <meta name="twitter:description" content="The lecture notes for MATH3030/4068: Multivariate Analysis / Applied Multivariate Statistics" />
  

<meta name="author" content="Prof.Â Richard Wilkinson" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="4-1-canonical-correlation-analysis.html"/>
<link rel="next" href="4-3-connection-with-linear-regression-when-q1.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied multivartiate statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="part-i-prerequisites.html"><a href="part-i-prerequisites.html"><i class="fa fa-check"></i>PART I: Prerequisites</a></li>
<li class="chapter" data-level="1" data-path="1-stat-prelim.html"><a href="1-stat-prelim.html"><i class="fa fa-check"></i><b>1</b> Statistical Preliminaries</a><ul>
<li class="chapter" data-level="1.1" data-path="1-1-multivariate-data.html"><a href="1-1-multivariate-data.html"><i class="fa fa-check"></i><b>1.1</b> Multivariate data</a></li>
<li class="chapter" data-level="1.2" data-path="1-2-summary-statistics.html"><a href="1-2-summary-statistics.html"><i class="fa fa-check"></i><b>1.2</b> Summary statistics</a></li>
<li class="chapter" data-level="1.3" data-path="1-3-graphical-techniques.html"><a href="1-3-graphical-techniques.html"><i class="fa fa-check"></i><b>1.3</b> Graphical techniques</a></li>
<li class="chapter" data-level="1.4" data-path="1-4-random-vectors-and-matrices.html"><a href="1-4-random-vectors-and-matrices.html"><i class="fa fa-check"></i><b>1.4</b> Random Vectors and Matrices</a></li>
<li class="chapter" data-level="1.5" data-path="1-5-unbiased-estimators.html"><a href="1-5-unbiased-estimators.html"><i class="fa fa-check"></i><b>1.5</b> Unbiased Estimators</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-linalg-prelim.html"><a href="2-linalg-prelim.html"><i class="fa fa-check"></i><b>2</b> Review of Matrix algebra</a><ul>
<li class="chapter" data-level="2.1" data-path="2-1-basic-definitions.html"><a href="2-1-basic-definitions.html"><i class="fa fa-check"></i><b>2.1</b> Basic definitions</a></li>
<li class="chapter" data-level="2.2" data-path="2-2-elementary-matrix-operations.html"><a href="2-2-elementary-matrix-operations.html"><i class="fa fa-check"></i><b>2.2</b> Elementary matrix operations</a></li>
<li class="chapter" data-level="2.3" data-path="2-3-linear-independence-and-determinants.html"><a href="2-3-linear-independence-and-determinants.html"><i class="fa fa-check"></i><b>2.3</b> Linear independence and determinants</a></li>
<li class="chapter" data-level="2.4" data-path="2-4-eigenvalues-and-eigenvectors.html"><a href="2-4-eigenvalues-and-eigenvectors.html"><i class="fa fa-check"></i><b>2.4</b> Eigenvalues and eigenvectors</a></li>
<li class="chapter" data-level="2.5" data-path="2-5-matrix-square-roots.html"><a href="2-5-matrix-square-roots.html"><i class="fa fa-check"></i><b>2.5</b> Matrix square roots</a></li>
<li class="chapter" data-level="2.6" data-path="2-6-singular-value-decomposition.html"><a href="2-6-singular-value-decomposition.html"><i class="fa fa-check"></i><b>2.6</b> Singular Value Decomposition</a></li>
<li class="chapter" data-level="2.7" data-path="2-7-the-centering-matrix.html"><a href="2-7-the-centering-matrix.html"><i class="fa fa-check"></i><b>2.7</b> The Centering Matrix</a></li>
<li class="chapter" data-level="2.8" data-path="2-8-quadratic-forms-and-ellipses.html"><a href="2-8-quadratic-forms-and-ellipses.html"><i class="fa fa-check"></i><b>2.8</b> Quadratic forms and ellipses</a></li>
<li class="chapter" data-level="2.9" data-path="2-9-lines-and-hyperplanes-in-mathbbrp.html"><a href="2-9-lines-and-hyperplanes-in-mathbbrp.html"><i class="fa fa-check"></i><b>2.9</b> Lines and Hyperplanes in <span class="math inline">\(\mathbb{R}^p\)</span></a></li>
<li class="chapter" data-level="2.10" data-path="2-10-vector-differentiation.html"><a href="2-10-vector-differentiation.html"><i class="fa fa-check"></i><b>2.10</b> Vector Differentiation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-ii-dimension-reduction-methods.html"><a href="part-ii-dimension-reduction-methods.html"><i class="fa fa-check"></i>PART II: Dimension reduction methods</a></li>
<li class="chapter" data-level="3" data-path="3-pca.html"><a href="3-pca.html"><i class="fa fa-check"></i><b>3</b> Principal component analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="3-1-principal-component-vectors-and-scores.html"><a href="3-1-principal-component-vectors-and-scores.html"><i class="fa fa-check"></i><b>3.1</b> Principal component vectors and scores</a></li>
<li class="chapter" data-level="3.2" data-path="3-2-properties-of-principal-components.html"><a href="3-2-properties-of-principal-components.html"><i class="fa fa-check"></i><b>3.2</b> Properties of principal components</a></li>
<li class="chapter" data-level="3.3" data-path="3-3-population-pca.html"><a href="3-3-population-pca.html"><i class="fa fa-check"></i><b>3.3</b> Population PCA</a></li>
<li class="chapter" data-level="3.4" data-path="3-4-an-alternative-derivation-of-pca.html"><a href="3-4-an-alternative-derivation-of-pca.html"><i class="fa fa-check"></i><b>3.4</b> An Alternative Derivation of PCA</a></li>
<li class="chapter" data-level="3.5" data-path="3-5-pca-under-transformations-of-variables.html"><a href="3-5-pca-under-transformations-of-variables.html"><i class="fa fa-check"></i><b>3.5</b> PCA under transformations of variables</a></li>
<li class="chapter" data-level="3.6" data-path="3-6-pca-based-on-boldsymbol-s-versus-pca-based-on-boldsymbol-r.html"><a href="3-6-pca-based-on-boldsymbol-s-versus-pca-based-on-boldsymbol-r.html"><i class="fa fa-check"></i><b>3.6</b> PCA based on <span class="math inline">\(\boldsymbol S\)</span> versus PCA based on <span class="math inline">\(\boldsymbol R\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-cca.html"><a href="4-cca.html"><i class="fa fa-check"></i><b>4</b> Canonical Correlation Analysis</a><ul>
<li class="chapter" data-level="4.1" data-path="4-1-canonical-correlation-analysis.html"><a href="4-1-canonical-correlation-analysis.html"><i class="fa fa-check"></i><b>4.1</b> Canonical Correlation Analysis</a></li>
<li class="chapter" data-level="4.2" data-path="4-2-the-full-set-of-canonical-correlations.html"><a href="4-2-the-full-set-of-canonical-correlations.html"><i class="fa fa-check"></i><b>4.2</b> The full set of canonical correlations</a></li>
<li class="chapter" data-level="4.3" data-path="4-3-connection-with-linear-regression-when-q1.html"><a href="4-3-connection-with-linear-regression-when-q1.html"><i class="fa fa-check"></i><b>4.3</b> Connection with linear regression when <span class="math inline">\(q=1\)</span></a></li>
<li class="chapter" data-level="4.4" data-path="4-4-population-cca.html"><a href="4-4-population-cca.html"><i class="fa fa-check"></i><b>4.4</b> Population CCA</a></li>
<li class="chapter" data-level="4.5" data-path="4-5-invarianceequivariance-properties-of-cca.html"><a href="4-5-invarianceequivariance-properties-of-cca.html"><i class="fa fa-check"></i><b>4.5</b> Invariance/equivariance properties of CCA</a></li>
<li class="chapter" data-level="4.6" data-path="4-6-testing-for-zero-canonical-correlation-coefficients.html"><a href="4-6-testing-for-zero-canonical-correlation-coefficients.html"><i class="fa fa-check"></i><b>4.6</b> Testing for zero canonical correlation coefficients</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-mds.html"><a href="5-mds.html"><i class="fa fa-check"></i><b>5</b> Multidimensional Scaling</a><ul>
<li class="chapter" data-level="5.1" data-path="5-1-multidimensional-scaling.html"><a href="5-1-multidimensional-scaling.html"><i class="fa fa-check"></i><b>5.1</b> Multidimensional Scaling</a></li>
<li class="chapter" data-level="5.2" data-path="5-2-principal-coordinates.html"><a href="5-2-principal-coordinates.html"><i class="fa fa-check"></i><b>5.2</b> Principal Coordinates</a></li>
<li class="chapter" data-level="5.3" data-path="5-3-similarity-measures.html"><a href="5-3-similarity-measures.html"><i class="fa fa-check"></i><b>5.3</b> Similarity measures</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-iii-inference-using-the-mvn-fix-figs-tabs.html"><a href="part-iii-inference-using-the-mvn-fix-figs-tabs.html"><i class="fa fa-check"></i>Part III: Inference using the MVN FIX FIGS TABS</a></li>
<li class="chapter" data-level="6" data-path="6-multinormal.html"><a href="6-multinormal.html"><i class="fa fa-check"></i><b>6</b> Multivariate Normal Distribution Theory</a><ul>
<li class="chapter" data-level="6.1" data-path="6-1-definition-and-properties-of-the-mvn.html"><a href="6-1-definition-and-properties-of-the-mvn.html"><i class="fa fa-check"></i><b>6.1</b> Definition and Properties of the MVN</a></li>
<li class="chapter" data-level="6.2" data-path="6-2-transformations.html"><a href="6-2-transformations.html"><i class="fa fa-check"></i><b>6.2</b> Transformations</a></li>
<li class="chapter" data-level="6.3" data-path="6-3-two-important-results-for-the-mvn.html"><a href="6-3-two-important-results-for-the-mvn.html"><i class="fa fa-check"></i><b>6.3</b> Two important results for the MVN</a></li>
<li class="chapter" data-level="6.4" data-path="6-4-the-wishart-distribution.html"><a href="6-4-the-wishart-distribution.html"><i class="fa fa-check"></i><b>6.4</b> The Wishart distribution</a></li>
<li class="chapter" data-level="6.5" data-path="6-5-hotellings-t2-distribution.html"><a href="6-5-hotellings-t2-distribution.html"><i class="fa fa-check"></i><b>6.5</b> Hotellingâs <span class="math inline">\(T^2\)</span> distribution</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-inference-in-1-and-2-samples-based-on-mvn.html"><a href="7-inference-in-1-and-2-samples-based-on-mvn.html"><i class="fa fa-check"></i><b>7</b> Inference in <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span> samples based on MVN</a><ul>
<li class="chapter" data-level="7.1" data-path="7-1-hypothesis-testing-boldsymbol-sigma-known.html"><a href="7-1-hypothesis-testing-boldsymbol-sigma-known.html"><i class="fa fa-check"></i><b>7.1</b> Hypothesis testing: <span class="math inline">\(\boldsymbol \Sigma\)</span> known</a></li>
<li class="chapter" data-level="7.2" data-path="7-2-hypothesis-testing-1-sample-case.html"><a href="7-2-hypothesis-testing-1-sample-case.html"><i class="fa fa-check"></i><b>7.2</b> Hypothesis testing - 1 sample case</a></li>
<li class="chapter" data-level="7.3" data-path="7-3-hypothesis-testing-2-sample-case.html"><a href="7-3-hypothesis-testing-2-sample-case.html"><i class="fa fa-check"></i><b>7.3</b> Hypothesis testing - 2 sample case</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-the-multivariate-linear-model.html"><a href="8-the-multivariate-linear-model.html"><i class="fa fa-check"></i><b>8</b> The Multivariate Linear Model</a><ul>
<li class="chapter" data-level="8.1" data-path="8-1-the-standard-univariate-linear-model.html"><a href="8-1-the-standard-univariate-linear-model.html"><i class="fa fa-check"></i><b>8.1</b> The standard univariate linear model</a></li>
<li class="chapter" data-level="8.2" data-path="8-2-multivariate-linear-model.html"><a href="8-2-multivariate-linear-model.html"><i class="fa fa-check"></i><b>8.2</b> Multivariate Linear Model</a></li>
<li class="chapter" data-level="8.3" data-path="8-3-one-way-manova.html"><a href="8-3-one-way-manova.html"><i class="fa fa-check"></i><b>8.3</b> One-way MANOVA</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-iv-classification-and-clustering.html"><a href="part-iv-classification-and-clustering.html"><i class="fa fa-check"></i>Part IV: Classification and Clustering</a></li>
<li class="chapter" data-level="9" data-path="9-lda.html"><a href="9-lda.html"><i class="fa fa-check"></i><b>9</b> Discriminant analysis - FIX THE FIGURES</a><ul>
<li class="chapter" data-level="9.1" data-path="9-1-maximum-likelihood-discriminant-rule.html"><a href="9-1-maximum-likelihood-discriminant-rule.html"><i class="fa fa-check"></i><b>9.1</b> Maximum likelihood discriminant rule</a></li>
<li class="chapter" data-level="9.2" data-path="9-2-the-sample-ml-discriminant-rule.html"><a href="9-2-the-sample-ml-discriminant-rule.html"><i class="fa fa-check"></i><b>9.2</b> The sample ML discriminant rule</a></li>
<li class="chapter" data-level="9.3" data-path="9-3-fishers-linear-discriminant-rule.html"><a href="9-3-fishers-linear-discriminant-rule.html"><i class="fa fa-check"></i><b>9.3</b> Fisherâs linear discriminant rule</a></li>
<li class="chapter" data-level="9.4" data-path="9-4-probability-of-misclassification.html"><a href="9-4-probability-of-misclassification.html"><i class="fa fa-check"></i><b>9.4</b> Probability of misclassification</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-cluster.html"><a href="10-cluster.html"><i class="fa fa-check"></i><b>10</b> Cluster Analysis</a><ul>
<li class="chapter" data-level="10.1" data-path="10-1-likelihood-based-clustering.html"><a href="10-1-likelihood-based-clustering.html"><i class="fa fa-check"></i><b>10.1</b> Likelihood-based clustering</a></li>
<li class="chapter" data-level="10.2" data-path="10-2-hierarchical-clustering-methods.html"><a href="10-2-hierarchical-clustering-methods.html"><i class="fa fa-check"></i><b>10.2</b> Hierarchical clustering methods</a></li>
<li class="chapter" data-level="10.3" data-path="10-3-further-points.html"><a href="10-3-further-points.html"><i class="fa fa-check"></i><b>10.3</b> Further Points</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li> <a href="https://rich-d-wilkinson.github.io/teaching.html" target="blank">University of Nottingham</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Multivariate Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-full-set-of-canonical-correlations" class="section level2">
<h2><span class="header-section-number">4.2</span> The full set of canonical correlations</h2>
<p>Let us first recap what we did in the previous section: we found the choices linear combinations of the <span class="math inline">\(x\)</span>-variables and linear combinations of <span class="math inline">\(y\)</span>-variables which
maximise the correlation, and expressed the answer in terms of quantities which arise in the SVD of <span class="math inline">\(\boldsymbol A\)</span>, where
<span class="math display">\[
\boldsymbol A\equiv \boldsymbol S_{\boldsymbol x\boldsymbol x}^{-1/2} \boldsymbol S_{\boldsymbol x\boldsymbol y}\boldsymbol S_{\boldsymbol y\boldsymbol y}^{-1/2}=\boldsymbol Q{\pmb \Xi} \boldsymbol R^\top=\sum_{j=1}^t \xi_j \boldsymbol q_j \boldsymbol r_j^\top,
\]</span>
with <span class="math inline">\(t\)</span> the rank of <span class="math inline">\(\boldsymbol A\)</span>, which in most examples is given by <span class="math inline">\(t=\min(p,q)\)</span>, and singular values <span class="math inline">\(\xi_1 \geq \xi_2 \geq \cdots \geq \xi_t&gt;0\)</span>.
Specifically, the maximum value of the correlation is <span class="math inline">\(\xi_1\)</span>, the optimal weights for the <span class="math inline">\(x\)</span>-variables are given by <span class="math inline">\(\boldsymbol a=\boldsymbol S_{\boldsymbol x\boldsymbol x}^{-1/2}\boldsymbol q_1=\boldsymbol a_1\)</span>, say, and
the optimal weights for the <span class="math inline">\(y\)</span>-varables are given by <span class="math inline">\(\boldsymbol b=\boldsymbol S_{\boldsymbol y\boldsymbol y}^{-1/2}\boldsymbol r_1 = \boldsymbol b_1\)</span>, say.</p>
<p>Can we repeat this process, as we did with PCA? Yes, we can. To obtain the second canonical correlation coefficient, plus the associated sets of weights, we need to solve the following optimisation problem:
<span class="math display" id="eq:cc2">\[\begin{equation}
\max_{\boldsymbol a,\, \boldsymbol b} \boldsymbol a^\top \boldsymbol S_{\boldsymbol x\boldsymbol y}\boldsymbol b
\tag{4.10}
\end{equation}\]</span>
subject to the constraints
<span class="math display" id="eq:conny21">\[\begin{equation}
\boldsymbol a^\top \boldsymbol S_{\boldsymbol x\boldsymbol x}\boldsymbol a= 1, \qquad \boldsymbol b^\top \boldsymbol S_{\boldsymbol y\boldsymbol y}\boldsymbol b=1,
\tag{4.11}
\end{equation}\]</span>
<span class="math display" id="eq:conny22">\[\begin{equation}
\boldsymbol a_1^\top \boldsymbol S_{\boldsymbol x\boldsymbol x} \boldsymbol a=0 \qquad \text{and} \qquad \boldsymbol b_1^\top \boldsymbol S_{\boldsymbol y\boldsymbol y}\boldsymbol b=0.
\tag{4.12}
\end{equation}\]</span>
Note that maximising <a href="4-2-the-full-set-of-canonical-correlations.html#eq:cc2">(4.10)</a> subject to <a href="4-2-the-full-set-of-canonical-correlations.html#eq:conny21">(4.11)</a> is very similar to the optimisation problem <a href="4-1-canonical-correlation-analysis.html#eq:opt27a">(4.6)</a> and <a href="4-1-canonical-correlation-analysis.html#eq:opt27b">(4.7)</a> considered in the previous section. What is
new are the constraints <a href="4-2-the-full-set-of-canonical-correlations.html#eq:conny22">(4.12)</a>, which take into account that we have already found the first canonical correlation. If for <span class="math inline">\(j=1,2\)</span> we write <span class="math inline">\(\tilde{\boldsymbol a}_j =\boldsymbol S_{\boldsymbol x\boldsymbol x}^{1/2} \boldsymbol a_j\)</span> and <span class="math inline">\(\tilde{\boldsymbol b}_j=\boldsymbol S_{\boldsymbol y\boldsymbol y}^{1/2} \boldsymbol b_j\)</span>, then it is seen from <a href="4-2-the-full-set-of-canonical-correlations.html#eq:conny22">(4.12)</a> that
<span class="math display">\[
\tilde{\boldsymbol a}_1^\top \tilde{\boldsymbol a}_2=0 \qquad \text{and} \qquad \tilde{\boldsymbol b}_1^\top \tilde{\boldsymbol b}_2=0.
\]</span>
Consequently, we may view constraints <a href="4-2-the-full-set-of-canonical-correlations.html#eq:conny22">(4.12)</a> as corresponding to orthogonality constraints (cf.Â PCA) in modified coordinate systems.</p>
<p>We now discuss the optimisation of <a href="4-2-the-full-set-of-canonical-correlations.html#eq:cc2">(4.10)</a>, <a href="4-2-the-full-set-of-canonical-correlations.html#eq:conny21">(4.11)</a> and <a href="4-2-the-full-set-of-canonical-correlations.html#eq:conny22">(4.12)</a>. At first glance it looks complex. However, using arguments very similar to those used to prove
Result 2.15 in Chapter 2, we may deduce the following:</p>
<ul>
<li>The maximum of <a href="4-2-the-full-set-of-canonical-correlations.html#eq:cc2">(4.10)</a> subject to constraints <a href="4-2-the-full-set-of-canonical-correlations.html#eq:conny21">(4.11)</a> and <a href="4-2-the-full-set-of-canonical-correlations.html#eq:conny22">(4.12)</a> is equal to <span class="math inline">\(\xi_2\)</span>, the second largest singular value of <span class="math inline">\(\boldsymbol A\)</span>.</li>
<li>The optimal weights for the <span class="math inline">\(x\)</span>-variables for the second canonical correlation are given by <span class="math inline">\(\boldsymbol a_2=\boldsymbol S_{\boldsymbol x\boldsymbol x}^{-1/2} \boldsymbol q_2\)</span>.</li>
<li>The optimal weights for the <span class="math inline">\(y\)</span>-variables for the second canonical correlation are given by <span class="math inline">\(\boldsymbol b_2=\boldsymbol S_{\boldsymbol y\boldsymbol y}^{-1/2}\boldsymbol r_2\)</span>.</li>
</ul>
<p>Consider now the general case of the <span class="math inline">\(k\)</span>th canonical correlation where <span class="math inline">\(2 \leq k \leq t\)</span>. In this case we replace <a href="4-2-the-full-set-of-canonical-correlations.html#eq:conny21">(4.11)</a> and <a href="4-2-the-full-set-of-canonical-correlations.html#eq:conny22">(4.12)</a> by, respectively,
<a href="4-2-the-full-set-of-canonical-correlations.html#eq:connyk1">(4.13)</a> and <a href="4-2-the-full-set-of-canonical-correlations.html#eq:connyk2">(4.14)</a> below, where
<span class="math display" id="eq:connyk1">\[\begin{equation}
\boldsymbol a^\top \boldsymbol S_{\boldsymbol x\boldsymbol x}\boldsymbol a= 1, \qquad \boldsymbol b^\top \boldsymbol S_{\boldsymbol y\boldsymbol y}\boldsymbol b=1,
\tag{4.13}
\end{equation}\]</span>
<span class="math display" id="eq:connyk2">\[\begin{equation}
\boldsymbol a_j^\top \boldsymbol S_{\boldsymbol x\boldsymbol x} \boldsymbol a=0 \qquad \text{and} \qquad \boldsymbol b_j^\top \boldsymbol S_{\boldsymbol y\boldsymbol y}\boldsymbol b=0, \qquad j=1, \ldots , k-1.
\tag{4.14}
\end{equation}\]</span>
Then the optimisation problem is
<span class="math display" id="eq:cck">\[\begin{equation}
\max_{\boldsymbol a, \, \boldsymbol b} \boldsymbol a^\top \boldsymbol S_{\boldsymbol x\boldsymbol y}\boldsymbol b
\tag{4.15}
\end{equation}\]</span>
subject to constraints <a href="4-2-the-full-set-of-canonical-correlations.html#eq:connyk1">(4.13)</a> and <a href="4-2-the-full-set-of-canonical-correlations.html#eq:connyk2">(4.14)</a>. The solution in the general case is as follows.</p>
<ul>
<li>The maximum of <a href="4-2-the-full-set-of-canonical-correlations.html#eq:cck">(4.15)</a> subject to constraints <a href="4-2-the-full-set-of-canonical-correlations.html#eq:connyk1">(4.13)</a> and <a href="4-2-the-full-set-of-canonical-correlations.html#eq:connyk2">(4.14)</a> is equal to <span class="math inline">\(\xi_k\)</span>, the <span class="math inline">\(k\)</span>th largest singular value of <span class="math inline">\(\boldsymbol A\)</span>.</li>
<li>The optimal weights for the <span class="math inline">\(x\)</span>-variables for the <span class="math inline">\(k\)</span>th canonical correlation are given by <span class="math inline">\(\boldsymbol a_k=\boldsymbol S_{\boldsymbol x\boldsymbol x}^{-1/2} \boldsymbol q_k\)</span>.</li>
<li>The optimal weights for the <span class="math inline">\(y\)</span>-variables for the <span class="math inline">\(k\)</span>th canonical correlation are given by <span class="math inline">\(\boldsymbol b_k=\boldsymbol S_{\boldsymbol y\boldsymbol y}^{-1/2}\boldsymbol r_k\)</span>.</li>
</ul>
<p>Terminology: we call <span class="math inline">\(\boldsymbol a_k\)</span> and <span class="math inline">\(\boldsymbol b_k\)</span> the <span class="math inline">\(k\)</span>th cc (weight) vectors for the <span class="math inline">\(x\)</span>-variables and <span class="math inline">\(y\)</span> variables, respectively.</p>
<p>We call <span class="math inline">\(\eta_{ik}=\boldsymbol a_k^\top (\boldsymbol x_i - \bar{\boldsymbol x})\)</span> and <span class="math inline">\(\psi_{ik}=\boldsymbol b_k^\top (\boldsymbol y_i -\bar{\boldsymbol y})\)</span>, <span class="math inline">\(i=1, \ldots , n\)</span>, the <span class="math inline">\(k\)</span>th cc scores for the <span class="math inline">\(x\)</span>-variables and the <span class="math inline">\(y\)</span>-variables, respectively.</p>
<p>Define the CC score vectors <span class="math inline">\({\pmb \eta}_k=(\eta_{1k}, \ldots , \eta_{nk})^\top\)</span> and <span class="math inline">\({\pmb \psi}_{k}=(\psi_{1k}, \ldots , \psi_{nk})^\top\)</span>. Then we have the following result.</p>

<div class="proposition">
<span id="prp:unnamed-chunk-3" class="proposition"><strong>Proposition 2.3  </strong></span>Assume that <span class="math inline">\(\boldsymbol S_{\boldsymbol x\boldsymbol x}\)</span> and <span class="math inline">\(\boldsymbol S_{\boldsymbol y\boldsymbol y}\)</span> both have full rank. Then for <span class="math inline">\(1 \leq k,\ell \leq t\)</span>,
<span class="math display">\[
r[\eta_k,  \psi_{\ell}]=\begin{cases} \xi_k &amp;\text{if} \quad k=\ell\\
0 &amp; \text{if} \quad k \neq \ell, \end{cases}
\]</span>
where <span class="math inline">\(t\)</span> is the rank of <span class="math inline">\(\boldsymbol A=\boldsymbol S_{\boldsymbol x\boldsymbol x}^{-1/2}\boldsymbol S_{\boldsymbol x\boldsymbol y} \boldsymbol S_{\boldsymbol y\boldsymbol y}^{-1/2}\)</span> and <span class="math inline">\(\xi_1 \geq \xi_2 \geq \cdots \xi_t &gt; 0\)</span> are the strictly positive singular values of <span class="math inline">\(\boldsymbol A\)</span>.
</div>

<p><strong>Example <a href="4-cca.html#exm:prem">4.1</a> (continued)</strong> From <a href="4-1-canonical-correlation-analysis.html#eq:SVDanalysis">(4.9)</a>, it is seen that the 2nd CC coefficient is given by <span class="math inline">\(\xi_2=0.508\)</span>. So the correlation between the second pair of CC variables is a lot smaller than the 1st CC coefficient, though still appreciably different from <span class="math inline">\(0\)</span>. We now calculate the 2nd CC weight vectors:
<span class="math display">\[
\boldsymbol a_2=\boldsymbol S_{\boldsymbol x\boldsymbol x}^{-1/2} \boldsymbol q_2 = \begin{pmatrix} 0.073 \\ 0.396 \end{pmatrix}
\qquad \text{and} \qquad
\boldsymbol b_2=\boldsymbol S_{\boldsymbol y\boldsymbol y}^{-1/2}\boldsymbol r_2=-\begin{pmatrix}0.062\\ 0.086  \end{pmatrix},
\]</span>
with standardised version (without the sign changes this time)
<span class="math display">\[
\boldsymbol a_2=\begin{pmatrix}0.181 \\ 0.984  \end{pmatrix}
\qquad \text{and} \qquad
\boldsymbol b_2=-\begin{pmatrix}0.589 \\ 0.808  \end{pmatrix},
\]</span>
and new variables
<span class="math display">\[
\eta_2=0.181*(W-\bar{W}) +0.984*(D -\bar{D})
\]</span>
and
<span class="math display">\[
\psi_2=-\{0.589*(F-\bar{F})+0.808*(A-\bar{A})\}.
\]</span>
Note that, to a good approximation, <span class="math inline">\(\eta_2\)</span> is measuring something similar to the number of draws and, approximately, <span class="math inline">\(\psi_2\)</span> is something related to the negative of total number of goals in a teamâs games. So large <span class="math inline">\(\psi_2\)</span> means relatively few goals in a teamâs games, and small (i.e.Â large negative) <span class="math inline">\(\psi_2\)</span> means a relatively large number of goals in a teamâs games.</p>
<p>Interpretation of the 2nd CC: teams that have a lot of draws tend to be in low-scoring games and/or teams that have few draws tend to be in high-scoring games.</p>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="4-1-canonical-correlation-analysis.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4-3-connection-with-linear-regression-when-q1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MATH3030.pdf"],
"toc": {
"collapse": "section"
},
"pandoc_args": "--top-level-division=[chapter|part]"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
